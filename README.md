<p align="center">
  <img src="https://img.shields.io/badge/Platform-Android-3DDC84?logo=android&logoColor=white" alt="Android"/>
  <img src="https://img.shields.io/badge/Min%20SDK-24-blue" alt="Min SDK 24"/>
  <img src="https://img.shields.io/badge/Kotlin-1.9-7F52FF?logo=kotlin&logoColor=white" alt="Kotlin"/>
  <img src="https://img.shields.io/badge/Compose-1.5-4285F4?logo=jetpack-compose&logoColor=white" alt="Compose"/>
  <img src="https://img.shields.io/badge/License-MIT-green" alt="License"/>
</p>

<h1 align="center">ğŸ¤– RunnableAI</h1>

<p align="center">
  <strong>On-device AI inference for Android</strong><br/>
  Chat â€¢ Speech-to-Text â€¢ Text-to-Speech
</p>

---

## âœ¨ Features

| Capability | Runtime | Model Format |
|------------|---------|--------------|
| ğŸ’¬ **LLM Chat** | llama.cpp | `.gguf` |
| ğŸ¤ **Speech Recognition (ASR)** | ONNX Runtime | `.onnx` |
| ğŸ”Š **Text-to-Speech (TTS)** | ExecuTorch / ONNX | `.pte` / `.onnx` |
| ğŸµ **Audio Codecs** | ONNX Runtime | `.onnx` |

- ğŸ“¦ **Zero bundled models** â€” download only what you need post-install
- ğŸ”’ **100% on-device** â€” no cloud, no data leaves your phone
- âš¡ **Hardware acceleration** â€” GPU layers for llama.cpp, NNAPI for ONNX
- ğŸ“± **Modern UI** â€” Jetpack Compose with Material 3

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        UI Layer                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ ChatScreen  â”‚  â”‚ModelsScreen â”‚  â”‚ ModelDetailScreenâ”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                          â”‚                                  â”‚
â”‚                   MainViewModel                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Domain Layer                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              InferenceOrchestrator                    â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚  â”‚
â”‚  â”‚  â”‚ChatHelperâ”‚  â”‚ TtsHelper â”‚  â”‚ AsrHelper â”‚          â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Backend Layer                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  LlamaBackend  â”‚ â”‚   OnnxBackend  â”‚ â”‚ExecuTorchBackendâ”‚  â”‚
â”‚  â”‚    (JNI)       â”‚ â”‚    (Maven)     â”‚ â”‚     (Maven)     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚          â”‚                                                   â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”                                            â”‚
â”‚    â”‚llama.cpp  â”‚  Native C++ via CMake FetchContent         â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Prerequisites

- **Docker** (recommended for reproducible builds)
- Android device with **arm64-v8a** architecture

### Build

```bash
# Clone the repository
git clone https://github.com/your-org/RunnableAI.git
cd RunnableAI

# Build APK using Docker
./scripts/build-in-docker.sh

# Output: app/build/outputs/apk/debug/app-debug.apk
```

### Install

```bash
adb install app/build/outputs/apk/debug/app-debug.apk
```

---

## ğŸ“¦ Model Catalog

Models are defined in [`app/src/main/assets/catalog.json`](app/src/main/assets/catalog.json):

```json
{
  "id": "llm-llama3-8b-q4",
  "name": "Llama 3 8B Instruct Q4",
  "task": "CHAT",
  "runtime": "LLAMA_CPP",
  "artifacts": [
    {
      "name": "model.gguf",
      "url": "https://huggingface.co/.../model.gguf",
      "sha256": "abc123...",
      "bytes": 4500000000
    }
  ],
  "requirements": {
    "min_ram_mb": 6000,
    "preferred_abi": "arm64-v8a"
  }
}
```

### Supported Fields

| Field | Values | Description |
|-------|--------|-------------|
| `task` | `CHAT`, `ASR`, `TTS`, `CODEC` | Model capability |
| `runtime` | `LLAMA_CPP`, `ONNX`, `EXECUTORCH` | Inference backend |
| `depends_on` | `["model-id"]` | Required dependencies |
| `artifacts` | `[{name, url, sha256, bytes}]` | Model files to download |

---

## ğŸ“ Storage Layout

```
<app-private-storage>/models/
â”œâ”€â”€ llm-llama3-8b-q4/
â”‚   â”œâ”€â”€ model.gguf
â”‚   â””â”€â”€ installed.json
â”œâ”€â”€ parakeet-tdt-0.6b-v2-onnx/
â”‚   â”œâ”€â”€ encoder-model.int8.onnx
â”‚   â”œâ”€â”€ decoder_joint-model.int8.onnx
â”‚   â”œâ”€â”€ vocab.txt
â”‚   â””â”€â”€ installed.json
â””â”€â”€ pocket-tts-executorch/
    â”œâ”€â”€ pocket_tts.pte
    â”œâ”€â”€ tokenizer.json
    â””â”€â”€ installed.json
```

---

## âš™ï¸ Technical Stack

| Component | Technology | Version |
|-----------|------------|---------|
| Language | Kotlin | 1.9.22 |
| UI | Jetpack Compose | 1.5.14 |
| Build | Gradle (Kotlin DSL) | 8.7 |
| Min SDK | Android 7.0 | API 24 |
| Target SDK | Android 14 | API 34 |
| NDK | r26d | 26.3.11579264 |

### Runtimes

| Runtime | Source | Notes |
|---------|--------|-------|
| **llama.cpp** | CMake FetchContent | Pinned commit `cff777f` |
| **ONNX Runtime** | Maven | `com.microsoft.onnxruntime:onnxruntime-android:1.17.1` |
| **ExecuTorch** | Maven | `org.pytorch:executorch-android:1.0.0` |

---

## ğŸ”§ Development

### Project Structure

```
app/src/main/
â”œâ”€â”€ java/ai/runnable/local/
â”‚   â”œâ”€â”€ backends/          # Runtime implementations
â”‚   â”‚   â”œâ”€â”€ llama/         # llama.cpp JNI wrapper
â”‚   â”‚   â”œâ”€â”€ onnx/          # ONNX Runtime wrapper
â”‚   â”‚   â””â”€â”€ executorch/    # ExecuTorch wrapper
â”‚   â”œâ”€â”€ data/              # Model catalog, downloads, storage
â”‚   â”œâ”€â”€ domain/            # Business logic, orchestration
â”‚   â””â”€â”€ ui/                # Compose screens & components
â”œâ”€â”€ cpp/                   # Native C++ (llama.cpp bindings)
â”œâ”€â”€ assets/                # catalog.json
â””â”€â”€ res/                   # Android resources
```

### Building Locally (without Docker)

Requires Android SDK + NDK installed:

```bash
./gradlew assembleDebug
```

### Running Lint

```bash
./gradlew lint
```

---

## ğŸ“‹ Roadmap

- [ ] Model-specific TTS pre/post-processing
- [ ] Model-specific ASR pre/post-processing  
- [ ] Streaming token generation callback
- [ ] Dedicated inference process + Binder IPC
- [ ] Model quantization selector
- [ ] Voice activity detection (VAD)

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

<p align="center">
  <sub>Built with â¤ï¸ for on-device AI</sub>
</p>
